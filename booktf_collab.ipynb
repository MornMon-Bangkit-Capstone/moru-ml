{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('data/RatingsV2.csv')\n",
    "books = pd.read_csv('data/BooksV2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "# books.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.merge(ratings, books, on='ISBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36323 entries, 0 to 36322\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           36323 non-null  int64  \n",
      " 1   User-ID              36323 non-null  int64  \n",
      " 2   ISBN                 36323 non-null  object \n",
      " 3   Book-Rating          36323 non-null  int64  \n",
      " 4   Book-Title           36323 non-null  object \n",
      " 5   Book-Author          36323 non-null  object \n",
      " 6   Year-Of-Publication  36323 non-null  int64  \n",
      " 7   Publisher            36323 non-null  object \n",
      " 8   Image-URL-L          36323 non-null  object \n",
      " 9   Author               35873 non-null  object \n",
      " 10  Summary              36323 non-null  object \n",
      " 11  Avg-Rating           36323 non-null  float64\n",
      " 12  Count-Rating         36323 non-null  float64\n",
      " 13  Genres               36323 non-null  object \n",
      "dtypes: float64(2), int64(4), object(8)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>User-ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36318</th>\n",
       "      <td>Judas, My Brother</td>\n",
       "      <td>9812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36319</th>\n",
       "      <td>The Dark Fields</td>\n",
       "      <td>9372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36320</th>\n",
       "      <td>Calico Bush</td>\n",
       "      <td>10744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36321</th>\n",
       "      <td>Calico Bush</td>\n",
       "      <td>13098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36322</th>\n",
       "      <td>Diplomatic Immunity</td>\n",
       "      <td>8932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36323 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Book-Title  User-ID\n",
       "0      Little Altars Everywhere        1\n",
       "1      Little Altars Everywhere        2\n",
       "2      Little Altars Everywhere        3\n",
       "3      Little Altars Everywhere        4\n",
       "4      Little Altars Everywhere        5\n",
       "...                         ...      ...\n",
       "36318         Judas, My Brother     9812\n",
       "36319           The Dark Fields     9372\n",
       "36320               Calico Bush    10744\n",
       "36321               Calico Bush    13098\n",
       "36322       Diplomatic Immunity     8932\n",
       "\n",
       "[36323 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings[['Book-Title', 'User-ID']].reset_index(drop=True)\n",
    " \n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>The Testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0345402871</td>\n",
       "      <td>Airframe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0345417623</td>\n",
       "      <td>Timeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0446310786</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0060168013</td>\n",
       "      <td>Pigs in Heaven</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN             Book-Title\n",
       "0  0440234743          The Testament\n",
       "1  0345402871               Airframe\n",
       "2  0345417623               Timeline\n",
       "3  0446310786  To Kill a Mockingbird\n",
       "4  0060168013         Pigs in Heaven"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = books[['ISBN', 'Book-Title']]\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['Item-ID'] = books['ISBN'].astype('category').cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5067 entries, 0 to 5066\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ISBN        5067 non-null   object\n",
      " 1   Book-Title  5067 non-null   object\n",
      " 2   Item-ID     5067 non-null   int16 \n",
      "dtypes: int16(1), object(2)\n",
      "memory usage: 89.2+ KB\n"
     ]
    }
   ],
   "source": [
    "books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item-ID</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2161</td>\n",
       "      <td>The Testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1158</td>\n",
       "      <td>Airframe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177</td>\n",
       "      <td>Timeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2413</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>Pigs in Heaven</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item-ID             Book-Title\n",
       "0     2161          The Testament\n",
       "1     1158               Airframe\n",
       "2     1177               Timeline\n",
       "3     2413  To Kill a Mockingbird\n",
       "4       61         Pigs in Heaven"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = books[['Item-ID', 'Book-Title']]\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5067"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['Item-ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 16:36:54.620195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 16:36:55.141598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-06 16:36:55.141789: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-06 16:36:56.835166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-06 16:36:56.835812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-06 16:36:56.835848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Text\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    " \n",
    "import tensorflow_recommenders as tfrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings.copy()\n",
    "books_df = books.copy()\n",
    " \n",
    " \n",
    "ratings_df.rename(columns = {'Book-Title': 'book_title', 'User-ID' : 'user_id'}, inplace=True)\n",
    "books_df.rename(columns = {'Book-Title': 'book_title', 'Item-ID' : 'item_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle5 as pickle\n",
    "\n",
    "# pickle.dump(books_df, open('Books.pkl', 'wb'))\n",
    "# # pickle.dump(ratings_df, open('Ratings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(books_df, open('Books.pkl', 'wb'))\n",
    "# # pickle.dump(ratings_df, open('Ratings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>book_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2161</td>\n",
       "      <td>The Testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1158</td>\n",
       "      <td>Airframe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177</td>\n",
       "      <td>Timeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2413</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>Pigs in Heaven</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id             book_title\n",
       "0     2161          The Testament\n",
       "1     1158               Airframe\n",
       "2     1177               Timeline\n",
       "3     2413  To Kill a Mockingbird\n",
       "4       61         Pigs in Heaven"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek = pickle.load(open('Books.pkl', 'rb'))\n",
    "# cek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 16:36:59.432349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-06 16:36:59.432398: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-06 16:36:59.432430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (iqbalf-TUF-Gaming-FX505DY-FX505DY): /proc/driver/nvidia/version does not exist\n",
      "2023-06-06 16:36:59.433040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# convert them to tf datasets\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings_df))\n",
    "books = tf.data.Dataset.from_tensor_slices(dict(books_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle5 as pickle\n",
    "# # \n",
    "# pickle.dump(books, open('Books.pkl', 'wb'))\n",
    "# pickle.dump(ratings, open('Ratings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item_id': <tf.Tensor: shape=(), dtype=int16, numpy=2161>, 'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'The Testament'>}\n",
      "{'item_id': <tf.Tensor: shape=(), dtype=int16, numpy=1158>, 'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Airframe'>}\n",
      "{'item_id': <tf.Tensor: shape=(), dtype=int16, numpy=1177>, 'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Timeline'>}\n",
      "{'item_id': <tf.Tensor: shape=(), dtype=int16, numpy=2413>, 'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'To Kill a Mockingbird'>}\n",
      "{'item_id': <tf.Tensor: shape=(), dtype=int16, numpy=61>, 'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Pigs in Heaven'>}\n"
     ]
    }
   ],
   "source": [
    "# get the first rows of the movies dataset\n",
    "for m in books.take(5):\n",
    "  print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Little Altars Everywhere'>, 'user_id': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
      "{'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Little Altars Everywhere'>, 'user_id': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
      "{'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Little Altars Everywhere'>, 'user_id': <tf.Tensor: shape=(), dtype=int64, numpy=3>}\n",
      "{'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Little Altars Everywhere'>, 'user_id': <tf.Tensor: shape=(), dtype=int64, numpy=4>}\n",
      "{'book_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Little Altars Everywhere'>, 'user_id': <tf.Tensor: shape=(), dtype=int64, numpy=5>}\n"
     ]
    }
   ],
   "source": [
    "for r in ratings.take(5):\n",
    "  print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/iqbalf/.local/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"book_title\": x[\"book_title\"],\n",
    "    \"user_id\": x[\"user_id\"]\n",
    "})\n",
    "books = books.map(lambda x: x[\"book_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle5 as pickle\n",
    "\n",
    "# pickle.dump(books, open('Books.pkl', 'wb'))\n",
    "# pickle.dump(ratings, open('Ratings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_vocabulary = tf.keras.layers.IntegerLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
    " \n",
    " \n",
    "book_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "book_titles_vocabulary.adapt(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle5 as pickle\n",
    "# # \n",
    "# pickle.dump(user_ids_vocabulary, open('User.pkl', 'wb'))\n",
    "# pickle.dump(book_titles_vocabulary, open('Ratings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookLensModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    " \n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      book_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    " \n",
    "    # Set up user and book representations.\n",
    "    self.user_model = user_model\n",
    "    self.book_model = book_model\n",
    " \n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    " \n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    " \n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    book_embeddings = self.book_model(features[\"book_title\"])\n",
    " \n",
    "    return self.task(user_embeddings, book_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user and book models.\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "book_model = tf.keras.Sequential([\n",
    "    book_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(book_titles_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    " \n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    books.batch(128).map(book_model)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 16:37:27.391454: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2023-06-06 16:37:27.463280: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 21s - factorized_top_k/top_1_categorical_accuracy: 2.4414e-04 - factorized_top_k/top_5_categorical_accuracy: 9.7656e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0020 - factorized_top_k/top_50_categorical_accuracy: 0.0095 - factorized_top_k/top_100_categorical_accuracy: 0.0212 - loss: 34068.6328 - regularization_loss: 0.0000e+00 - total_loss: 34068.6328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 16:37:28.221361: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2023-06-06 16:37:28.288821: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/9 [=====>........................] - ETA: 5s - factorized_top_k/top_1_categorical_accuracy: 1.2207e-04 - factorized_top_k/top_5_categorical_accuracy: 4.8828e-04 - factorized_top_k/top_10_categorical_accuracy: 9.7656e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0063 - factorized_top_k/top_100_categorical_accuracy: 0.0182 - loss: 34068.9688 - regularization_loss: 0.0000e+00 - total_loss: 34068.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 16:37:29.065343: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 8s 689ms/step - factorized_top_k/top_1_categorical_accuracy: 2.7531e-05 - factorized_top_k/top_5_categorical_accuracy: 2.4778e-04 - factorized_top_k/top_10_categorical_accuracy: 4.6802e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0028 - factorized_top_k/top_100_categorical_accuracy: 0.0078 - loss: 33099.2660 - regularization_loss: 0.0000e+00 - total_loss: 33099.2660\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 6s 681ms/step - factorized_top_k/top_1_categorical_accuracy: 1.9272e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0039 - factorized_top_k/top_10_categorical_accuracy: 0.0115 - factorized_top_k/top_50_categorical_accuracy: 0.0812 - factorized_top_k/top_100_categorical_accuracy: 0.1532 - loss: 32166.2381 - regularization_loss: 0.0000e+00 - total_loss: 32166.2381\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 6s 669ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0884 - factorized_top_k/top_5_categorical_accuracy: 0.3300 - factorized_top_k/top_10_categorical_accuracy: 0.4448 - factorized_top_k/top_50_categorical_accuracy: 0.6663 - factorized_top_k/top_100_categorical_accuracy: 0.7489 - loss: 22593.7377 - regularization_loss: 0.0000e+00 - total_loss: 22593.7377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f15dc38c190>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = BookLensModel(user_model, book_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    " \n",
    "# Train for 3 epochs.\n",
    "model.fit(ratings.batch(4096), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f15dc4cc910>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    books.batch(100).map(lambda title: (title, model.book_model(title))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommendations for user 42: [b'The Education of Little Tree' b'Virtual Light' b'Daggerspell'\n",
      " b'Ball Four' b'A Star Called Henry' b'Too Many Cooks'\n",
      " b'Rendezvous with Rama' b'Oryx and Crake' b'The Ugly Little Boy'\n",
      " b'Islands in the Net']\n"
     ]
    }
   ],
   "source": [
    "# Get some recommendations.\n",
    "_, titles = index(np.array([225]))\n",
    "print(f\"Top 10 recommendations for user 42: {titles[0, :20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16525, 64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the users embeddings\n",
    "users_embdeddings = user_model.weights[1].numpy()\n",
    " \n",
    "# get the mapping of the user ids from the vocabulary\n",
    "users_idx_name = user_ids_vocabulary.get_vocabulary()\n",
    " \n",
    "# print the shape\n",
    "users_embdeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot convert a Tensor of dtype resource to a NumPy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/iqbalf/Documents/VsCode/Bangkit/dump/booktf_collab.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/iqbalf/Documents/VsCode/Bangkit/dump/booktf_collab.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle5\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/iqbalf/Documents/VsCode/Bangkit/dump/booktf_collab.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/iqbalf/Documents/VsCode/Bangkit/dump/booktf_collab.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pickle\u001b[39m.\u001b[39;49mdump(user_ids_vocabulary, \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mUser.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/iqbalf/Documents/VsCode/Bangkit/dump/booktf_collab.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pickle\u001b[39m.\u001b[39mdump(book_titles_vocabulary, \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRatings.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1080\u001b[0m, in \u001b[0;36m_EagerTensorBase.__reduce__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__reduce__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 1080\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor, (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy(),)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numpy_internal()\n\u001b[1;32m   1122\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot convert a Tensor of dtype resource to a NumPy array."
     ]
    }
   ],
   "source": [
    "import pickle5 as pickle\n",
    "# \n",
    "pickle.dump(user_ids_vocabulary, open('User.pkl', 'wb'))\n",
    "pickle.dump(book_titles_vocabulary, open('Ratings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5068, 64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the books embeddings\n",
    "books_embdeddings = book_model.weights[1].numpy()\n",
    " \n",
    "# get the mapping of the book tiles from the vocabulary\n",
    "book_idx_name = book_titles_vocabulary.get_vocabulary()\n",
    " \n",
    "# print the shape of the books embeddings\n",
    "books_embdeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.21487163, -0.33324146,  0.9501462 , -0.58884704,  1.0146874 ,\n",
       "         0.28926226, -0.7476183 , -0.20930994,  0.8841889 , -0.7895067 ,\n",
       "        -0.5174846 , -0.97731936,  1.1640527 , -1.1527156 ,  0.98859453,\n",
       "         0.7890409 ,  1.0802909 , -0.5588331 , -1.0707998 , -1.2162035 ,\n",
       "         0.60587025,  0.23181476,  0.3863407 , -0.12047958,  0.554301  ,\n",
       "        -0.05788615, -1.000889  , -0.81643796, -0.39185366,  0.9952024 ,\n",
       "        -0.78250194,  0.4419828 ,  1.0879096 , -0.9481119 , -0.8707744 ,\n",
       "         0.6163281 , -0.5477191 ,  0.13775998, -0.84431195,  0.3503885 ,\n",
       "         0.6223601 , -0.31119248, -0.85468984, -0.7074049 , -0.0397219 ,\n",
       "        -0.8284998 , -0.8443066 ,  0.08627954,  0.22105277, -0.74575716,\n",
       "        -0.5971295 , -0.871295  , -0.66443837, -0.14558679, -0.83842623,\n",
       "         0.40966845,  1.0335081 ,  0.8783546 ,  0.65080297,  1.0187967 ,\n",
       "         0.6595291 ,  0.24447107, -0.61808515,  0.0329106 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_model.predict([\"Harry Potter and the Prisoner of Azkaban\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    " \n",
    "# get the cosine similarity of all pairs\n",
    "books_similarity = 1-pairwise_distances(books_embdeddings, metric='cosine')\n",
    " \n",
    "# get the upper triangle in order to take the unique pairs\n",
    "books_similarity = np.triu(books_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_A</th>\n",
       "      <th>book_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[UNK]</td>\n",
       "      <td>[UNK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zuleika Dobson</td>\n",
       "      <td>Zuleika Dobson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zorba the Greek</td>\n",
       "      <td>Zorba the Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zombie Lover</td>\n",
       "      <td>Zombie Lover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wolfskin</td>\n",
       "      <td>Broken Angels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wolfskin</td>\n",
       "      <td>Bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wolfskin</td>\n",
       "      <td>Breaking and Entering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wolfskin</td>\n",
       "      <td>Blackthorn Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Wolfskin</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             book_A                 book_B\n",
       "0             [UNK]                  [UNK]\n",
       "1                 e                      e\n",
       "2    Zuleika Dobson         Zuleika Dobson\n",
       "3   Zorba the Greek        Zorba the Greek\n",
       "4      Zombie Lover           Zombie Lover\n",
       "..              ...                    ...\n",
       "95         Wolfskin          Broken Angels\n",
       "96         Wolfskin                    Bro\n",
       "97         Wolfskin  Breaking and Entering\n",
       "98         Wolfskin      Blackthorn Winter\n",
       "99         Wolfskin                  Black\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_A = np.take(book_idx_name, np.where((books_similarity>0.8))[0])\n",
    "book_B = np.take(book_idx_name, np.where((books_similarity>0.8))[1])\n",
    " \n",
    "similar_books = pd.DataFrame({'book_A':book_A, 'book_B':book_B})\n",
    "similar_books.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8936 entries, 0 to 8935\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   book_A  8936 non-null   object\n",
      " 1   book_B  8936 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 139.8+ KB\n"
     ]
    }
   ],
   "source": [
    "similar_books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16525, 5068)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the product of users and movies embeddings\n",
    "product_matrix = np.matmul(users_embdeddings, np.transpose(books_embdeddings))\n",
    " \n",
    "# get the shape of the product matrix \n",
    "product_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3549"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_idx_name.index('Harry Potter and the Prisoner of Azkaban')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Point of Origin', 'The Book of Fours',\n",
       "       'The Lost Language of Cranes', 'The Bear and the Dragon',\n",
       "       'Puerto Vallarta Squeeze', 'The Grass Crown', 'Ginger Pye',\n",
       "       'Homecoming', 'The Murder of Roger Ackroyd', 'The River'],\n",
       "      dtype='<U106')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score of movies for book 42\n",
    "book_42_books = product_matrix[book_idx_name.index(\"Harry Potter and the Prisoner of Azkaban\"),:]\n",
    " \n",
    "# return the top 10 books \n",
    "np.take(book_idx_name, book_42_books.argsort()[::-1])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Education of Little Tree', 'Virtual Light', 'Daggerspell',\n",
       "       'Ball Four', 'A Star Called Henry', 'Too Many Cooks',\n",
       "       'Rendezvous with Rama', 'Oryx and Crake', 'The Ugly Little Boy',\n",
       "       'Islands in the Net'], dtype='<U106')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score of books for user 42\n",
    "user_42_books = product_matrix[users_idx_name.index(225),:]\n",
    " \n",
    "# return the top 10 books \n",
    "np.take(book_idx_name, user_42_books.argsort()[::-1])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Education of Little Tree', 'Virtual Light', 'Daggerspell',\n",
       "       'Ball Four', 'A Star Called Henry', 'Too Many Cooks',\n",
       "       'Rendezvous with Rama', 'Oryx and Crake', 'Islands in the Net',\n",
       "       'The Murder of Roger Ackroyd', 'Only Human',\n",
       "       'Puerto Vallarta Squeeze', 'Perelandra', 'The Joy Luck Club',\n",
       "       'For Love of Mother-Not', 'Witches Abroad', 'The Europeans',\n",
       "       'The House in Paris', 'Bloodsucking Fiends',\n",
       "       'For Special Services'], dtype='<U106')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_books = ratings_df.query('user_id==225')['book_title'].values\n",
    " \n",
    "np.setdiff1d(np.take(book_idx_name, user_42_books.argsort()[::-1]), seen_books, assume_unique=True)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "# Export the query model.\n",
    "# with tempfile.TemporaryDirectory() as tmp:\n",
    "#   path = os.path.join(tmp, \"model\")\n",
    "path = os.path.join('./', \"model\")\n",
    "  # Save the index.\n",
    "tf.saved_model.save(index, path)\n",
    " \n",
    "  # Load it back; can also be done in TensorFlow Serving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'The Education of Little Tree' b'Virtual Light' b'Daggerspell'\n",
      " b'Ball Four' b'A Star Called Henry']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "path = os.path.join('./', \"model\")\n",
    "loaded = tf.saved_model.load(path)\n",
    "\n",
    "# Pass a user id in, get top predicted movie titles back.\n",
    "scores, titles = loaded([225])\n",
    " \n",
    "print(f\"Recommendations: {titles[0][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[2.5905342, 2.2789183, 2.225389 , 2.13339  , 2.1259413, 2.036004 ,\n",
       "         1.9745611, 1.9689205, 1.929327 , 1.9255413]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
       " array([[b'The Education of Little Tree', b'Virtual Light',\n",
       "         b'Daggerspell', b'Ball Four', b'A Star Called Henry',\n",
       "         b'Too Many Cooks', b'Rendezvous with Rama', b'Oryx and Crake',\n",
       "         b'The Ugly Little Boy', b'Islands in the Net']], dtype=object)>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded([225])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
